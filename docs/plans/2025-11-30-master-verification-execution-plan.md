# Master Verification & Completion Execution Plan

> **For Claude:** REQUIRED SUB-SKILLS:
> - Use superpowers:executing-plans to implement this plan in batches with review checkpoints
> - Use superpowers:systematic-debugging for EVERY bug (mandatory 4-phase investigation)
> - Use superpowers:root-cause-tracing when bugs are deep in call stack
> - Use superpowers:dispatching-parallel-agents for code audit (Domain 5)

**Goal:** Complete verification of all 33 application features with systematic debugging for every bug, achieving honest 95%+ completion with production deployment

**Architecture:** Database-first awesome list platform with hierarchical navigation (21 categories, 102 subcategories, 90 sub-subcategories), GitHub bidirectional sync, AI enrichment via Claude Haiku 4.5, and admin approval workflows

**Tech Stack:** React 18, TypeScript, Express, Drizzle ORM, Supabase PostgreSQL, Docker Compose, Redis 7, Nginx, Claude AI, GitHub API

**Current Honest Completion:** 33-35% (11/33 features verified working)
**Target Completion:** 95% (31/33 features + production deployed)
**Total Tasks:** 516 granular tasks + ~140 bug-fixing tasks
**Estimated Duration:** 33-37 hours across 5 verification domains

---

## Executive Summary

### Context: 5 Sessions of Work Completed

**Sessions 1-2** (5.5 hours): Infrastructure migration
- Migrated database schema (19 tables) to Supabase
- Updated 70 API endpoints for Supabase Auth
- Built Docker infrastructure (web, redis, nginx)
- Fixed 7 critical bugs (frontend unblocking)
- Claimed: "90% complete" - **Actually: ~18% (6 features verified)**

**Session 3** (12 hours): Admin panel build
- Built 13 admin React components
- Added 11 new API endpoints
- Created 18,462 lines of documentation
- Fixed 8 bugs through MCP validation
- Claimed: "85% complete" - **Actually: ~25% (some admin UI working)**

**Session 4** (2 hours): Code audit + documentation
- Found 5 more bugs through ultrathink
- Created comprehensive README, ARCHITECTURE.md, DATABASE_SCHEMA.md
- Dispatched 4 parallel code audit agents
- Deleted 28 unused components (-4,611 lines)
- Claimed: "90%+ production ready" - **Actually: ~27% (minimal new verification)**

**Session 5** (10 hours): Data model architecture fix
- Fixed critical data integrity (12 orphaned categories, 1,269 affected resources)
- Implemented hierarchical categories API (3-level nesting)
- Enhanced GitHub import to create hierarchy tables
- Removed all static JSON (87,089 lines deleted)
- Fixed 2 bugs, verified 2 workflows
- **Honest claim: 33-35%** (11/33 features verified)

### The Honest Truth

**What's Actually Working** (11/33 features = 33%):
1. âœ… Browse & Navigate (hierarchical, 21 categories)
2. âœ… Search (full-text, 2,646 resources)
3. âœ… Login/Logout (email/password via Supabase)
4. âœ… Admin Dashboard (stats display correctly)
5. âœ… Database (2,646 resources, complete schema)
6. âœ… Docker Infrastructure (containers healthy)
7. âœ… Hierarchical Navigation (3-level sidebar)
8. âœ… Data Integrity (0 orphaned resources)
9. âœ… GitHub Import (hierarchy extraction working)
10. âœ… Bookmark Add (backend verified via curl)
11. âœ… Resource Submit â†’ Approve (backend verified via curl)

**What's Built But UNVERIFIED** (22/33 features = 67%):
- Bookmarks (remove, view page)
- Favorites (all operations)
- User Profile & Stats
- Learning Journeys (browse, enroll, progress)
- User Preferences & Recommendations
- Search & Filter combinations
- Admin Resource Editing
- **Bulk Operations (NEVER TESTED - HIGH RISK)**
- Admin User Management
- GitHub Export (code exists, untested)
- **AI Enrichment (NEVER TESTED - HIGH RISK)**
- Link Checker, Awesome-lint validation
- Security (RLS with real users, XSS, SQL injection)
- Performance (benchmarking, load testing)
- Production Deployment

### Gaps in Previous Sessions

**Why Completion Was Overestimated:**
1. **Code creation confused with verification** - Building components != features working
2. **API endpoint existence confused with testing** - Returning 401 != tested
3. **Single workflow tested, all claimed working** - Approval tested once, claimed "admin features complete"
4. **No 3-layer validation** - Network OR Database OR UI, not all 3
5. **No bug-fixing buffer** - Assumed happy path, reality is 60% overhead for bugs

**Bugs Found Through Verification:**
- Session 2: Found 7 bugs when actually testing frontend (not just looking at code)
- Session 3: Found 8 bugs through MCP browser testing (visual inspection missed them)
- Session 4: Found 5 bugs through ultrathink + database queries
- Session 5: Found 2 bugs during workflow testing
- **Total: 22 bugs** - Average 4.4 bugs per session when actually testing

**Pattern:** Every session that claims "complete" without comprehensive testing finds bugs in next session.

### This Master Plan's Approach

**Principles:**
1. **Test EVERYTHING** - All 70 endpoints, all 33 features, with 3-layer validation
2. **Expect bugs** - 31-48 more bugs likely remain (based on 22 found / 33% verified ratio)
3. **Systematic debugging mandatory** - NO quick fixes, root cause analysis required
4. **Evidence required** - Screenshots + SQL + Network logs for EVERY test
5. **Honest completion tracking** - Only count features when fully verified

**Execution Strategy:**
- 5 verification domains (not artificial "sessions")
- 516 granular tasks (2-5 min each)
- 140 bug-fixing tasks (60% overhead buffer)
- Batch execution with checkpoints every 20-30 tasks
- Mandatory skill invocations at specific points

---

## Domain Overview & Task Distribution

### Domain 1: Core API Verification (Database Foundation Complete âœ…)

**Status:** 95% complete (database verified in Session 5)
**Remaining:** 5% (final audit, documentation)
**Tasks:** 10 tasks
**Duration:** 1 hour
**Priority:** LOW (foundation solid)

**Completed in Session 5:**
- âœ… Schema reconciliation (sessions/users removed)
- âœ… Foreign key verification (15 FKs tested)
- âœ… Index verification (77 indexes, EXPLAIN ANALYZE)
- âœ… RLS policy testing (17 policies, anon access verified)

**Remaining Tasks:**
1. Document FK cascade test results (10 min)
2. Document index performance matrix (10 min)
3. Document RLS policy inventory (10 min)
4. Create database audit summary (15 min)
5. Commit database verification complete (5 min)

---

### Domain 2: API Endpoint Testing (60 Endpoints Untested)

**Status:** 14% complete (10/70 endpoints tested)
**Remaining:** 86% (60 endpoints with 3-layer validation)
**Tasks:** 180 tasks (60 endpoints Ã— 3 subtasks each)
**Duration:** 10-12 hours
**Priority:** CRITICAL (foundation for all feature testing)

**Structure per Endpoint:**
1. Call endpoint with proper auth (curl or browser) - 3 min
2. Verify database changes (SQL query) - 3 min
3. Document result in API_TEST_RESULTS.md - 2 min
4. **IF FAILS:** Invoke systematic-debugging, fix, rebuild, retest - +30 min

**High Priority Endpoints** (Critical Path - 20 endpoints):
- POST /api/bookmarks/:id (add bookmark)
- DELETE /api/bookmarks/:id (remove bookmark)
- GET /api/bookmarks (view bookmarks)
- POST /api/favorites/:id
- DELETE /api/favorites/:id
- GET /api/favorites
- POST /api/resources (submit resource)
- GET /api/resources/:id
- PUT /api/resources/:id/approve
- PUT /api/resources/:id/reject
- POST /api/admin/resources/bulk (bulk operations - CRITICAL)
- PUT /api/admin/resources/:id (resource editing)
- POST /api/admin/export (GitHub export)
- POST /api/admin/import-github (GitHub import)
- POST /api/enrichment/start (AI enrichment)
- GET /api/enrichment/jobs/:id (job monitoring)
- DELETE /api/enrichment/jobs/:id (job cancellation)
- POST /api/journeys/:id/start (journey enrollment)
- PUT /api/journeys/:id/progress (step completion)
- PUT /api/admin/users/:id/role (role management)

**Medium Priority** (20 endpoints):
- User preferences, user stats, analytics, validation, etc.

**Low Priority** (20 endpoints):
- Legacy/utility endpoints, secondary features

**References:**
- Full endpoint list: CLAUDE.md lines 195-290
- API test matrix template: docs/API_TEST_RESULTS.md
- Existing tested endpoints: API_TEST_RESULTS.md lines 24-44

---

### Domain 3: User Workflow Validation (10 Features Untested)

**Status:** 10% complete (1/10 user features verified - basic browse/search)
**Remaining:** 90% (9 features with end-to-end testing)
**Tasks:** 150 tasks (from SESSION_6_EXECUTION_PLAN.md)
**Duration:** 11 hours
**Priority:** HIGH (core user experience)

**Workflows Defined in SESSION_6_EXECUTION_PLAN.md:**

**Workflow 1: Account Creation** (Tasks 1-20, 2 hours)
- Navigate /login â†’ Sign up
- Fill email, password, confirm password
- Submit signup form
- Verify confirmation email (Supabase inbox)
- Confirm email link
- Verify user in auth.users
- First login
- Verify session created
- Navigate to profile
- Verify default preferences created
- **Skills:** systematic-debugging if signup fails

**Workflow 2: Favorites Flow** (Tasks 21-45, 2 hours)
- Login as test user
- Navigate to category
- Click favorite button (star icon)
- **Verify Network:** POST /api/favorites/:id â†’ 200
- **Verify Database:** SELECT * FROM user_favorites WHERE user_id=X
- **Verify UI:** Button state changes, toast notification
- Navigate to profile
- **Verify UI:** Favorite shown in profile
- Click remove favorite
- **Verify Database:** Row deleted
- **Verify UI:** Removed from profile
- **Skills:** systematic-debugging if favorites not persisting

**Workflow 3: Profile & Stats** (Tasks 46-60, 1 hour)
- Navigate /profile
- **Verify UI:** Stats accurate (bookmark count, favorite count, submission count, streak days)
- **Verify Database:** Query counts match UI
- Test profile tabs (Overview, Favorites, Bookmarks, Submissions)
- Verify data loads in each tab
- **Skills:** systematic-debugging if stats calculation wrong

**Workflow 4: Search & Filter** (Tasks 61-90, 1.5 hours)
- Test text search ("ffmpeg" â†’ expect ~158 results)
- Test category filter
- Test tag filter
- Test combined search + category
- Test clear filters
- Verify debouncing (300ms delay)
- Test empty results
- Test special characters
- **Verify Database:** SELECT COUNT(*) matches UI results
- **Skills:** systematic-debugging if search not finding resources

**Workflow 5: Learning Journeys** (Tasks 91-130, 2 hours)
- **PREREQUISITE:** Seed learning journey via SQL or admin panel
- Browse /journeys page
- View journey details
- Click "Start Journey"
- **Verify Database:** user_journey_progress row created
- Navigate to first step
- Click "Mark Complete"
- **Verify Database:** completedSteps array updated
- View progress on profile
- **Verify UI:** Percentage calculation correct
- Complete all steps
- **Verify Database:** completed_at populated
- **Skills:** systematic-debugging if enrollment fails, root-cause-tracing if progress not saving

**Workflow 6: Preferences & Recommendations** (Tasks 131-150, 1.5 hours)
- Navigate to /profile/settings
- Set preferred categories (select 3)
- Set skill level (intermediate)
- Set learning goals (enter 3)
- Save preferences
- **Verify Database:** user_preferences table updated
- Request recommendations
- **Verify:** Recommendations match preferences
- Change preferences
- **Verify:** Recommendations change
- **Skills:** systematic-debugging if preferences not persisting

**References:** Complete task details in docs/plans/SESSION_6_EXECUTION_PLAN.md

**Bug Expectation:** 10-15 bugs across user workflows
**Bug Buffer:** 3 hours (25 min per bug Ã— 12 bugs average)

---

### Domain 4: Admin Workflow Validation (12 Features Untested)

**Status:** 8% complete (1/12 admin features - dashboard stats working)
**Remaining:** 92% (11 features including RISKY bulk operations)
**Tasks:** 195 tasks (from SESSION_7_EXECUTION_PLAN.md)
**Duration:** 13 hours
**Priority:** CRITICAL (bulk operations NEVER tested, HIGH RISK)

**CRITICAL WARNING:** Bulk operations have NEVER been fully tested end-to-end. Code exists but:
- Unknown if transactions work
- Unknown if audit logging works for bulk actions
- Unknown if UI refreshes correctly
- Unknown if RLS allows bulk operations
- **Risk Level: VERY HIGH**

**Workflow 7: Resource Editing** (Tasks 1-20, 1.5 hours)
**File:** client/src/components/admin/ResourceEditModal.tsx
- Admin login
- Navigate /admin/resources
- Click dropdown on resource
- Click Edit
- **Verify:** Modal opens with pre-filled data (React Hook Form)
- Change description
- Click Save
- **Verify Network:** PUT /api/admin/resources/:id â†’ 200
- **Verify Database:** description updated, updated_at changed
- **Verify UI Public:** Public page shows updated description
- **Skills:** systematic-debugging if modal doesn't open, root-cause-tracing if save fails

**Workflow 8: Bulk Approve** (Tasks 21-45, 2 hours)
**File:** server/routes.ts:XXX (bulk endpoint)
- Create 5 pending resources (via curl for speed)
- **Verify Database:** 5 rows with status='pending'
- Admin navigate /admin/resources
- Filter status='pending'
- Select all 5 (checkboxes)
- **Verify UI:** "5 resources selected" displayed
- Click Bulk Approve
- Confirm in modal
- **Wait for completion** (may take 2-5 seconds)
- **Verify Network:** POST /api/admin/resources/bulk with action='approve'
- **Verify Database:** All 5 have status='approved', approved_by set, approved_at set
- **CRITICAL Verify Database:** SELECT COUNT(*) FROM resource_audit_log WHERE resource_id IN (...) - Expect 5 entries
- **Verify UI:** Table refreshes, selection cleared, toast "Successfully approved 5 resources"
- **Verify Public:** All 5 visible on public category pages
- **Skills:** systematic-debugging if bulk fails, root-cause-tracing if transactions partially complete

**Workflow 9: Bulk Reject** (Tasks 46-65, 1.5 hours)
- Similar to Workflow 8 but action='reject'
- Verify status='rejected'
- Verify NOT visible publicly
- Verify audit log entries
- **Skills:** systematic-debugging if reject fails

**Workflow 10: Bulk Archive** (Tasks 66-85, 1.5 hours)
- Create 5 approved resources
- Select 5
- Click Bulk Archive
- Verify status='archived'
- Verify removed from public pages
- Verify still in admin panel with archived filter
- Verify audit log entries
- **Skills:** systematic-debugging if archive fails

**Workflow 11: Bulk Tag Assignment** (Tasks 86-110, 2 hours)
**Most Complex Bulk Operation**
- Select 3 approved resources
- Click "Add Tags"
- Enter: "session-test, validated, bulk-tagged"
- Save
- **Verify Database:** SELECT * FROM tags WHERE name IN (...) - Expect 3 rows
- **Verify Database:** SELECT * FROM resource_tags WHERE resource_id IN (...) - Expect 9 rows (3Ã—3)
- **Verify UI:** Tags appear on resource cards
- **Skills:** systematic-debugging if tags not created, root-cause-tracing if junction creation fails

**Workflow 12: User Management** (Tasks 111-125, 1 hour)
- Navigate /admin/users
- List users (verify pagination)
- Find test user
- Change role to "moderator"
- **Verify Database:** auth.users.raw_user_meta_data->>'role' = 'moderator'
- Test moderator access (can they access some admin features?)
- Suspend user
- **Verify:** Blocked from login
- **Skills:** systematic-debugging if role change fails

**Workflow 13: GitHub Export** (Tasks 126-155, 2.5 hours)
**File:** server/github/formatter.ts
- Navigate /admin/github
- Configure repository URL
- Click "Export to GitHub" (dry-run first)
- **Verify:** Markdown generated
- Check structure (# headings, - list items, categories alphabetical)
- Run awesome-lint validation:
  ```bash
  npx awesome-lint [exported-file.md]
  ```
- If errors: Fix in formatter.ts, re-export, re-lint
- Iterate until validation passes
- Actual export (create GitHub commit)
- **Verify Database:** github_sync_history row created
- View sync history in admin panel
- **Skills:** systematic-debugging if export fails, root-cause-tracing if markdown malformed

**Workflow 14: AI Enrichment** (Tasks 156-195, 3 hours)
**File:** server/ai/enrichmentService.ts
**NEVER TESTED - HIGH RISK**
- Verify Anthropic API key configured
- Navigate /admin/enrichment
- Select filter: "all"
- Batch size: 5 (small for testing)
- Click "Start Enrichment"
- **Verify Database:** enrichment_jobs row created (status='pending')
- Monitor enrichment_queue (5 rows, watch status updates pending â†’ processing â†’ completed)
- Wait for job completion (5 resources Ã— 30 sec/resource = ~2.5 min)
- **Verify Database:** resources.metadata updated with Claude analysis
- **Verify Database:** tags table has new tags from AI
- **Verify Database:** resource_tags junctions created (~15 for 5 resources Ã— 3 tags avg)
- **Verify UI:** Navigate to enriched resources, verify tags display
- **Skills:** systematic-debugging if job stalls, root-cause-tracing if Claude API errors

**References:** SESSION_7_EXECUTION_PLAN.md for complete 195-task breakdown

**Bug Expectation:** 12-18 bugs (bulk operations HIGH RISK)
**Bug Buffer:** 3 hours

---

### Domain 5: Production Hardening (Security + Performance + Deployment)

**Status:** 0% complete (nothing tested)
**Remaining:** 100% (all security, performance, deployment tasks)
**Tasks:** 115 tasks (from SESSION_8_EXECUTION_PLAN.md)
**Duration:** 9 hours
**Priority:** REQUIRED for production deployment

**Workflow 15: Security Testing** (Tasks 1-55, 4 hours)

**Phase 1: User Isolation (RLS Testing)**
- Create User A, User B via Supabase
- User A bookmarks resource
- **Verify Database:** user_bookmarks has 1 row for User A
- User B login
- Navigate /bookmarks as User B
- **Verify UI:** SHOULD NOT see User A's bookmark (RLS blocks)
- **Verify Database:** Query as User B context, expect 0 rows
- **IF FAILS:** **CRITICAL SECURITY BUG** - STOP, invoke systematic-debugging
- **Skills:** systematic-debugging if RLS broken, root-cause-tracing to find policy gap

**Phase 2: XSS Testing**
- Submit resource with title: `<script>alert('XSS')</script>`
- Admin approve
- Navigate to public page
- **Verify:** Script rendered as text (escaped), no alert popup
- **IF FAILS:** **CRITICAL XSS VULNERABILITY** - STOP immediately
- **Skills:** systematic-debugging, security audit

**Phase 3: SQL Injection Testing**
- Search with: `'; DROP TABLE resources; --`
- **Verify Database:** Resources table still exists, count unchanged
- Test in multiple inputs (title, description, search, filters)
- **Skills:** systematic-debugging if SQL injection succeeds

**Phase 4: Rate Limiting**
- Send 100 requests in 1 minute
- **Verify:** 429 Too Many Requests after 60 requests (per nginx.conf)
- **Skills:** systematic-debugging if rate limiting not working

**Workflow 16: Performance Benchmarking** (Tasks 56-80, 2.5 hours)

**Phase 1: Lighthouse Audit**
- Run on Homepage, Category page, Admin dashboard
- Target: Performance score > 80
- Document: FCP, LCP, TTI, CLS metrics
- **Skills:** performance-engineer if scores low

**Phase 2: API Load Testing**
```bash
npm install -g autocannon
autocannon -c 10 -d 30 http://localhost:3000/api/resources
autocannon -c 100 -d 60 http://localhost:3000/api/resources  # 100 concurrent
```
- Target: p95 < 200ms, no errors
- **Skills:** database-optimizer if slow queries found

**Phase 3: Database Query Optimization**
- Run EXPLAIN ANALYZE on slow queries
- Identify missing indexes
- Add indexes if needed
- Re-benchmark

**Workflow 17: Production Deployment** (Tasks 81-110, 2.5 hours)

**Phase 1: SSL Configuration**
- Obtain SSL certificates (certbot or manual)
- Copy to docker/nginx/ssl/
- Update nginx.conf with HTTPS
- Test HTTPS locally
- Verify HTTP â†’ HTTPS redirect

**Phase 2: Production Environment**
- Create .env.production with real credentials
- Set production Supabase URL
- Configure OAuth providers (GitHub, Google) in Supabase dashboard
- Set WEBSITE_URL to production domain

**Phase 3: Deployment**
- Deploy to staging environment
- Run smoke tests on staging
- Deploy to production
- Verify health checks
- Set up monitoring (uptime, error tracking)
- Configure automated backups

**Phase 4: Code Cleanup** (Tasks 111-115, 30 min)
- Remove 269 console.log statements (from Session 4 audit)
- Fix 48 `any` types
- Delete any remaining unused files
- Final build verification

**References:** SESSION_8_EXECUTION_PLAN.md for complete 115-task breakdown

**Bug Expectation:** 6-10 bugs (SSL issues, deployment config errors)

---

## Mandatory Testing Protocol (ALL Domains)

### 3-Layer Verification (NO MOCKS - Shannon Principle)

**EVERY feature test requires ALL 3 layers to pass:**

**Layer 1: Network Verification**
- API endpoint called (via curl, browser, or Puppeteer)
- Correct HTTP status code (200, 201, not 401/500)
- Response body matches expected structure
- Authorization headers present when required

**Layer 2: Database Verification**
- SQL query confirms data persistence
- Correct values in database
- Foreign keys intact
- Timestamps populated
- Audit log entries created (where applicable)

**Layer 3: UI Verification**
- Browser shows correct state
- Visual elements updated
- Toast notifications appear
- State changes reflected

**Example - Bookmark Add Test:**
```
Layer 1 (Network): POST /api/bookmarks/:uuid â†’ 200 OK, body: {"success":true}
Layer 2 (Database): SELECT * FROM user_bookmarks WHERE resource_id=X â†’ 1 row with correct user_id
Layer 3 (UI): Navigate /bookmarks â†’ Resource appears in list, screenshot evidence
```

**Failure Handling:**
- If Layer 1 fails: API bug â†’ systematic-debugging â†’ Fix endpoint
- If Layer 2 fails: Database bug â†’ systematic-debugging â†’ Fix storage method or RLS
- If Layer 3 fails: Frontend bug â†’ systematic-debugging â†’ Fix component

---

### Systematic Debugging Protocol (Mandatory for ALL Bugs)

**When ANY test fails, IMMEDIATELY:**

**Phase 1: Root Cause Investigation (15 min)**
- Copy exact error message
- Check: Recent git commits (git log -5)
- Gather evidence: Docker logs, browser console, network tab, database query
- Reproduce: Can it be consistently reproduced? Steps?
- Document in: docs/bugs/BUG_[DATE]_[DESCRIPTION].md

**Phase 2: Pattern Analysis (10 min)**
- Find working example: Similar feature that works correctly
- Compare: What's different between working and broken?
- Check dependencies: What does this broken feature need?
- Review: Similar bugs in past sessions (search bug docs)

**Phase 3: Hypothesis Testing (10 min)**
- Form hypothesis: "I think X is broken because Y"
- Design minimal test: Smallest change to test hypothesis
- Execute test: Make one change, observe result
- Result: CONFIRMED (hypothesis correct) or REJECTED (hypothesis wrong)
- If rejected: Return to Phase 2, form new hypothesis

**Phase 4: Fix Implementation (15-30 min)**
- Identify root cause (confirmed from Phase 3)
- Edit relevant file(s)
- Apply fix at source (not symptom)
- Run: `npm run check` (TypeScript validation)
- Rebuild Docker: `docker-compose down && docker-compose build --no-cache web && docker-compose up -d`
- Wait: 30 seconds for startup
- Retest: Execute failing test from beginning
- Verify: All 3 layers now pass
- Document fix in bug report
- Commit: Atomic commit with bug reference

**TOTAL TIME per bug:** 50-70 minutes (explains why 60% overhead buffer needed)

**Example Bug Document Template:**
```markdown
# Bug: Bulk Approve Fails on Third Resource

**Found:** 2025-11-30 14:23:00
**Task:** Workflow 8, Task 34 (Database verification)
**Severity:** HIGH (breaks core admin feature)

## Phase 1: Root Cause Investigation
- Error: "Transaction failed: deadlock detected"
- Stack trace: [...server logs...]
- Reproduced: YES (3/3 attempts)
- Steps: Select 5 resources â†’ Bulk approve â†’ 3rd resource fails

## Phase 2: Pattern Analysis
- Working example: Single approve works correctly
- Difference: Bulk uses transaction, single doesn't
- Dependencies: Needs FK locks on approved_by
- Similar: No similar bugs in past sessions

## Phase 3: Hypothesis
- Theory: FK lock contention when updating multiple resources
- Test: Add FOR UPDATE SKIP LOCKED to query
- Result: CONFIRMED (bulk now completes)

## Phase 4: Fix
- Root cause: Missing row-level locking in transaction
- File: server/storage.ts:XXX
- Fix: Added SKIP LOCKED clause to bulk update query
- Verification: Bulk approve 10 resources â†’ All succeed, 0 deadlocks
- Commit: abc1234 "fix: Add row-level locking to bulk operations"
```

---

### Iterative Bug Fixing Workflow

**Critical Pattern (Must Follow):**

```
Test Feature A
  â†“
Passes all 3 layers?
  â”œâ”€ YES â†’ Document evidence â†’ Next feature
  â””â”€ NO â†’ BUG FOUND
      â†“
  STOP testing immediately
      â†“
  Create bug document (docs/bugs/BUG_XXX.md)
      â†“
  Invoke systematic-debugging skill
      â†“
  Follow 4-phase protocol
      â†“
  Fix identified root cause
      â†“
  Edit relevant file(s)
      â†“
  Docker rebuild: down â†’ build --no-cache â†’ up -d â†’ wait 30s
      â†“
  RESTART test from beginning (not from failure point)
      â†“
  Re-verify all 3 layers
      â†“
  Passes?
    â”œâ”€ YES â†’ Document fix â†’ Commit â†’ Continue to next feature
    â””â”€ NO â†’ REPEAT systematic-debugging with new evidence
```

**NEVER:**
- Continue past failed test
- "Document bug, fix later"
- Quick fixes without root cause analysis
- Skip Docker rebuild after code changes
- Continue mid-test after bug fix (always restart test from beginning)

---

## Task Inventory Matrix

### Domain 1: Database Verification (10 tasks, 1 hour) - 95% Complete

| Task | File | Duration | Tool | Status |
|------|------|----------|------|--------|
| 1.1 | Document FK results | docs/DB_FK_VERIFICATION.md | 10min | Bash | â³ PENDING |
| 1.2 | Document index matrix | docs/DB_INDEX_PERFORMANCE.md | 10min | Supabase MCP | â³ PENDING |
| 1.3 | Document RLS policies | docs/DB_RLS_INVENTORY.md | 10min | Supabase MCP | â³ PENDING |
| 1.4 | Create audit summary | docs/DB_AUDIT_SUMMARY.md | 15min | Bash | â³ PENDING |
| 1.5 | Commit verification | git commit | 5min | Bash | â³ PENDING |

---

### Domain 2: API Endpoint Testing (180 tasks, 10-12 hours) - 14% Complete

**High Priority Endpoints (60 tasks = 20 endpoints Ã— 3 subtasks)**

#### Bookmark Endpoints (9 tasks, 30 min)

**Task 2.1: POST /api/bookmarks/:id**
- Duration: 10 min (3 layers + potential bug)
- Tool: curl + Supabase MCP + superpowers-chrome
- Status: â³ PENDING

Step 1: Get admin JWT token
```bash
# Open http://localhost:3000/login
# Login as admin@test.com / Admin123!
# Open DevTools â†’ Application â†’ localStorage
# Copy: sb-jeyldoypdkgsrfdhdcmm-auth-token â†’ access_token
export ADMIN_TOKEN="[paste_here]"
```

Step 2: Call endpoint
```bash
curl -X POST http://localhost:3000/api/bookmarks/afc5937b-28eb-486c-961f-38b5d2418b2a \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json"
```

Expected: 200 OK or 201 Created

Step 3: Verify database
```sql
-- Via Supabase MCP
SELECT user_id, resource_id, notes, created_at
FROM user_bookmarks
WHERE user_id = '58c592c5-548b-4412-b4e2-a9df5cac5397'
  AND resource_id = 'afc5937b-28eb-486c-961f-38b5d2418b2a';
```

Expected: 1 row, created_at within last minute

Step 4: Verify UI
```
Navigate: http://localhost:3000/bookmarks
Verify: Resource appears in list
Screenshot: evidence
```

**IF FAILS:**
- Invoke: systematic-debugging skill
- Create: docs/bugs/BUG_BOOKMARK_ADD_FAILS.md
- Follow 4-phase protocol
- Fix, rebuild, retest

Document Result:
- File: docs/API_TEST_RESULTS.md line 29
- Format: `| POST /api/bookmarks/:id | âœ… PASS | 200 | {...} | Row created | Screenshot |`

**Task 2.2: DELETE /api/bookmarks/:id** (10 min)
- Similar structure: curl â†’ SQL verify deletion â†’ UI verify removed
- **IF FAILS:** systematic-debugging

**Task 2.3: GET /api/bookmarks** (10 min)
- Call endpoint, verify returns array, matches database count
- **IF FAILS:** systematic-debugging

**Continue for all 20 High Priority endpoints...**

---

### Domain 3: User Workflows (150 tasks, 11 hours) - 10% Complete

**Reference:** Full 150-task breakdown in docs/plans/SESSION_6_EXECUTION_PLAN.md

**Summary of 6 Workflows:**
- Account Creation: 20 tasks, 2h
- Favorites Flow: 25 tasks, 2h
- Profile & Stats: 15 tasks, 1h
- Search & Filter: 30 tasks, 1.5h
- Learning Journeys: 40 tasks, 2.5h (includes prerequisite seeding)
- Preferences & Recommendations: 20 tasks, 1.5h

**Each workflow follows:**
- Navigate to feature
- Perform action
- **Verify Network:** API call successful
- **Verify Database:** Data persisted
- **Verify UI:** State updated
- **IF FAILS:** systematic-debugging â†’ root-cause-tracing if needed
- Document evidence
- Commit when verified

**Example Task from Workflow 2 (Favorites):**

**Task 3.25: Add Favorite**
- File: client/src/components/resource/FavoriteButton.tsx
- Duration: 10 min
- Tool: superpowers-chrome + Supabase MCP

Step 1: Navigate to category
```
Navigate: http://localhost:3000/category/encoding-codecs
Wait for page load
```

Step 2: Find favorite button in page.md
```
Read auto-captured page.md
Search for: star icon or "favorite" button
Note selector for Task 3.26
```

Step 3: Click favorite button
```
Click selector from Step 2
Wait for response
```

Step 4: Verify Network (Layer 1)
```
Check network: POST /api/favorites/:uuid
Expect: 200 OK
```

Step 5: Verify Database (Layer 2)
```sql
SELECT user_id, resource_id, created_at
FROM user_favorites
WHERE user_id = '58c592c5-548b-4412-b4e2-a9df5cac5397'
  AND resource_id = '[clicked_resource_uuid]';
```
Expect: 1 row

Step 6: Verify UI (Layer 3)
```
Check: Button state changed (filled star vs outline)
Check: Toast notification "Added to favorites"
Screenshot: evidence
```

**IF FAILS:**
- STOP testing
- Invoke: systematic-debugging
- Check: FavoriteButton component logic
- Check: POST /api/favorites/:id endpoint
- Check: RLS policies on user_favorites table
- Find root cause, fix, rebuild, restart Task 3.25

---

### Domain 4: Admin Workflows (195 tasks, 13 hours) - 8% Complete

**Reference:** Full 195-task breakdown in docs/plans/SESSION_7_EXECUTION_PLAN.md

**CRITICAL RISK AREAS:**
- Bulk operations (NEVER fully tested, complex transactions)
- GitHub export (markdown generation, awesome-lint validation)
- AI enrichment (external API, async job processing)

**Each admin workflow requires:**
- Admin authentication (JWT token)
- Permission verification (isAdmin check)
- Database transaction integrity
- Audit logging verification (CRITICAL for compliance)
- Public visibility changes verification

**Example Task from Workflow 8 (Bulk Approve):**

**Task 4.34: Verify Database Updated**
- Duration: 5 min
- Tool: Supabase MCP
- Dependencies: Task 4.33 (Bulk approve button clicked)

Step 1: Query resources table
```sql
SELECT id, title, status, approved_by, approved_at
FROM resources
WHERE id IN (
  '[id1]', '[id2]', '[id3]', '[id4]', '[id5]'
)
ORDER BY title;
```

Expected Results (ALL must be true):
- âœ… All 5 rows have status = 'approved'
- âœ… All 5 have approved_by = '58c592c5-548b-4412-b4e2-a9df5cac5397' (admin ID)
- âœ… All 5 have approved_at within last minute (recent timestamp)
- âœ… No rows with status = 'pending' (all updated)

Step 2: Verify audit log (CRITICAL)
```sql
SELECT resource_id, action, performed_by, changes, created_at
FROM resource_audit_log
WHERE resource_id IN ('[id1]', '[id2]', '[id3]', '[id4]', '[id5]')
  AND action LIKE '%approve%'
ORDER BY created_at DESC;
```

Expected Results:
- âœ… Exactly 5 audit entries (one per resource)
- âœ… action = 'approved' or 'bulk_approved'
- âœ… performed_by = admin UUID
- âœ… created_at within last minute

**IF DATABASE VERIFICATION FAILS:**
- **Scenario A:** Some approved, some still pending
  - **Issue:** Transaction partially committed (CRITICAL)
  - **Action:** STOP, invoke root-cause-tracing
  - **Analysis:** Trace bulk endpoint â†’ storage method â†’ database transaction
  - **Find:** Where transaction fails or partially rolls back
  - **Fix:** Add proper transaction handling or rollback on error

- **Scenario B:** All approved but NO audit log entries
  - **Issue:** Audit logging not implemented for bulk operations (CRITICAL)
  - **Action:** STOP, invoke systematic-debugging
  - **Analysis:** Check if audit log call in bulk endpoint exists
  - **Fix:** Add audit log creation to bulk operation transaction
  - **Verify:** Audit log helper function called for each resource

- **Scenario C:** All approved but approved_by is NULL
  - **Issue:** req.user not passed to storage method
  - **Action:** STOP, invoke systematic-debugging
  - **Fix:** Pass req.user.id to storage.bulkApproveResources()

**AFTER FIX:**
- Rebuild Docker (mandatory)
- Clean test data (DELETE test resources)
- RESTART from Task 4.21 (Create 5 pending resources)
- Re-execute entire bulk approve workflow
- Verify: All 5 tests in Task 4.34 pass

---

### Docker Rebuild Schedule

**MANDATORY rebuild after EVERY code change:**

```bash
# Standard rebuild (uses cache)
docker-compose down
docker-compose build web
docker-compose up -d
sleep 30  # Wait for startup
docker-compose ps  # Verify healthy
docker-compose logs web | tail -20  # Check for errors
```

**Use --no-cache when:**
- Bug fix didn't take effect (cache issue)
- Frontend changes not appearing
- Mysterious "old code" behavior
- After major refactoring

```bash
docker-compose build --no-cache web
```

**Rebuild Required After:**
- âœ… Any file edit in server/
- âœ… Any file edit in client/src/
- âœ… Any file edit in shared/
- âœ… package.json changes
- âœ… tsconfig.json changes
- âŒ docs/ file changes (no rebuild needed)
- âŒ .env file changes (restart sufficient: docker-compose restart web)

**Verification After Rebuild:**
- Health check: `curl http://localhost:3000/api/health` â†’ {"status":"ok"}
- No startup errors: `docker-compose logs web | grep -i error` â†’ Empty or expected errors only
- TypeScript compiled: No "compilation failed" in logs
- Containers healthy: `docker-compose ps` â†’ All show "healthy"

---

## Evidence Collection Requirements

**For EVERY test, collect:**

**1. Network Evidence**
- HTTP method + URL + status code
- Request headers (especially Authorization)
- Request body (if POST/PUT)
- Response body
- Response time
- Save to: Screenshot of network tab OR curl output

**2. Database Evidence**
- SQL query executed
- Complete result set
- Row counts
- Timestamps (verify recency)
- Save to: SQL query results in test doc

**3. UI Evidence**
- Screenshot of page before action
- Screenshot of page after action
- Page.md content (auto-captured by superpowers-chrome)
- Console errors (if any)
- Save to: /tmp/ directory with semantic naming

**Evidence Naming Convention:**
```
/tmp/session-[N]-[workflow]-[step]-[result].png

Examples:
/tmp/session-6-favorites-add-success.png
/tmp/session-7-bulk-approve-db-verified.png
/tmp/session-8-xss-test-escaped.png
```

**Evidence Organization:**
- All screenshots: /tmp/ directory
- All SQL results: Embed in test documentation
- All network logs: Embed in test documentation
- Summary: docs/TESTING_EVIDENCE_SUMMARY.md (created at end)

---

## Completion Gate Definitions

### Domain 1: Database - COMPLETE when:
- âœ… All 15 foreign keys documented with test results
- âœ… All 77 indexes documented with EXPLAIN ANALYZE results
- âœ… All 17 RLS policies tested with anon/user/admin contexts
- âœ… Schema matches shared/schema.ts exactly
- âœ… No orphaned data (all FKs valid)
- âœ… Audit summary document created

### Domain 2: API Endpoints - COMPLETE when:
- âœ… All 70 endpoints called with proper auth
- âœ… All endpoints documented in API_TEST_RESULTS.md
- âœ… All 3 layers verified for each endpoint
- âœ… All bugs found and fixed
- âœ… All evidence collected (network logs, SQL)

### Domain 3: User Workflows - COMPLETE when:
- âœ… All 6 user workflows executed end-to-end
- âœ… All 3 layers verified for each workflow
- âœ… All bugs found and fixed
- âœ… All evidence collected (150+ screenshots)
- âœ… User experience smooth (no confusing errors)

### Domain 4: Admin Workflows - COMPLETE when:
- âœ… All 8 admin workflows verified
- âœ… Bulk operations work (approve, reject, archive, tag)
- âœ… Audit logging proven functional for ALL operations
- âœ… GitHub export generates awesome-lint compliant markdown
- âœ… AI enrichment completes successfully with tags created
- âœ… All admin features work without bugs

### Domain 5: Production - COMPLETE when:
- âœ… Security tested (RLS, XSS, SQL injection, rate limiting)
- âœ… Performance benchmarked (Lighthouse > 80, p95 < 200ms)
- âœ… Deployed to production with SSL
- âœ… Monitoring active (uptime, errors)
- âœ… Backups configured
- âœ… Code cleanup complete (no console.logs, no any types)

**OVERALL PROJECT COMPLETE when:**
- âœ… All 5 domains meet completion gates
- âœ… 31/33 features verified working (95%+)
- âœ… Production deployed and stable for 24 hours
- âœ… Comprehensive evidence documented (500+ screenshots, SQL queries)

---

## Skill Invocation Map

**This section defines EXACTLY when to invoke each skill:**

### systematic-debugging Skill

**Invoke When:**
- ANY test fails (network, database, or UI layer)
- Unexpected behavior observed
- Error messages appear
- Data doesn't persist
- UI doesn't update

**Expected Invocations:** 31-48 times (one per expected bug)

**Invocation Points in Plan:**
- Domain 2, every endpoint test: "IF FAILS: Invoke systematic-debugging"
- Domain 3, every user workflow: "IF FAILS: Invoke systematic-debugging"
- Domain 4, every admin workflow: "IF FAILS: Invoke systematic-debugging"
- Domain 5, security tests: "IF VULNERABILITY: Invoke systematic-debugging"

**Protocol:** MANDATORY 4-phase investigation (Root Cause â†’ Pattern â†’ Hypothesis â†’ Fix)

---

### root-cause-tracing Skill

**Invoke When:**
- Bug is deep in call stack
- Error occurs in nested function calls
- Systematic-debugging Phase 3 can't identify break point
- Transaction fails with unclear cause
- Data corruption detected

**Expected Invocations:** 8-15 times (for complex bugs)

**Example Invocation Points:**
- Domain 4, Task 4.34: "IF transaction partially completes: Invoke root-cause-tracing to trace bulk approve â†’ storage method â†’ SQL transaction â†’ find failure point"
- Domain 3, Task 3.100: "IF journey progress not saving: Invoke root-cause-tracing to trace enrollJourney â†’ updateProgress â†’ database â†’ find break"

**Protocol:** Trace execution path backwards from error to find original trigger

---

### executing-plans Skill

**Invoke:** At START of this plan execution

**Usage:** Current session should invoke with this master plan

**Protocol:**
- Load plan
- Review critically
- Execute in batches (default 20-30 tasks per batch)
- Report after each batch
- Wait for feedback
- Continue until complete

**Note:** User is already trying to invoke this - that's what the /superpowers:execute-plan command was

---

### dispatching-parallel-agents Skill

**Invoke When:** Code audit needed (Domain 5 only)

**Invocation Point:** Domain 5, Cleanup phase
```
Dispatch 4 parallel agents:
- Agent 1: Audit server/ for console.logs (269 found in Session 4)
- Agent 2: Audit client/ for any types (48 found in Session 4)
- Agent 3: Find unused imports
- Agent 4: Find duplicate code patterns

Wait for all 4 to complete
Consolidate findings
Remove dead code systematically
```

**Expected Invocations:** 1 time (for code audit)

---

### test-driven-development Skill

**Invoke When:** Building NEW features (not testing existing)

**NOT applicable for this plan** - We're verifying existing features, not building new ones

**Note:** Original writing-plans skill emphasizes TDD, but this is a VERIFICATION plan, not a BUILD plan

---

### finishing-a-development-branch Skill

**Invoke:** AFTER all 5 domains complete

**Invocation Point:** After Domain 5 cleanup complete
```
All tasks verified
All bugs fixed
All evidence collected
All documentation updated

â†’ Invoke: finishing-a-development-branch
â†’ Present options: Merge, PR, cleanup
â†’ Execute user's choice
```

**Expected Invocations:** 1 time (final)

---

## Detailed Task Breakdown by Domain

### Domain 2: API Endpoint Testing - Complete Task List

**Bookmark Endpoints** (Tasks 2.1-2.3, 30 min)
- 2.1: POST /api/bookmarks/:id - Add bookmark with auth
- 2.2: DELETE /api/bookmarks/:id - Remove bookmark
- 2.3: GET /api/bookmarks - List user bookmarks

**Favorite Endpoints** (Tasks 2.4-2.6, 30 min)
- 2.4: POST /api/favorites/:id
- 2.5: DELETE /api/favorites/:id
- 2.6: GET /api/favorites

**Resource Endpoints** (Tasks 2.7-2.12, 60 min)
- 2.7: POST /api/resources (submit with auth)
- 2.8: GET /api/resources/:id
- 2.9: PUT /api/resources/:id (admin edit)
- 2.10: DELETE /api/resources/:id (admin delete)
- 2.11: PUT /api/resources/:id/approve (admin)
- 2.12: PUT /api/resources/:id/reject (admin)

**Bulk Operations** (Tasks 2.13-2.16, 60 min)
- 2.13: POST /api/admin/resources/bulk with action='approve'
- 2.14: POST /api/admin/resources/bulk with action='reject'
- 2.15: POST /api/admin/resources/bulk with action='archive'
- 2.16: POST /api/admin/resources/bulk with action='tag'

**Admin Endpoints** (Tasks 2.17-2.30, 90 min)
- 2.17: GET /api/admin/stats
- 2.18: GET /api/admin/resources (with filters)
- 2.19: GET /api/admin/users
- 2.20: PUT /api/admin/users/:id/role
- 2.21: POST /api/admin/export
- 2.22: POST /api/admin/import-github
- 2.23: POST /api/admin/validate
- 2.24: POST /api/admin/check-links
- 2.25: GET /api/admin/validation-status
- 2.26: POST /api/admin/seed-database
- 2.27: GET /api/admin/analytics
- 2.28: GET /api/admin/audit-log
- 2.29: PUT /api/admin/settings
- 2.30: DELETE /api/admin/resources/:id

**GitHub Endpoints** (Tasks 2.31-2.37, 60 min)
- 2.31: POST /api/github/configure
- 2.32: POST /api/github/import
- 2.33: POST /api/github/export
- 2.34: GET /api/github/sync-status
- 2.35: GET /api/github/sync-status/:id
- 2.36: GET /api/github/sync-history
- 2.37: POST /api/github/process-queue

**Enrichment Endpoints** (Tasks 2.38-2.41, 45 min)
- 2.38: POST /api/enrichment/start
- 2.39: GET /api/enrichment/jobs
- 2.40: GET /api/enrichment/jobs/:id
- 2.41: DELETE /api/enrichment/jobs/:id (cancel)

**Journey Endpoints** (Tasks 2.42-2.46, 45 min)
- 2.42: GET /api/journeys
- 2.43: GET /api/journeys/:id
- 2.44: POST /api/journeys/:id/start (enroll)
- 2.45: PUT /api/journeys/:id/progress (mark step complete)
- 2.46: GET /api/journeys/:id/progress

**User Endpoints** (Tasks 2.47-2.52, 45 min)
- 2.47: GET /api/user/progress
- 2.48: GET /api/user/submissions
- 2.49: GET /api/user/journeys
- 2.50: POST /api/user/preferences
- 2.51: GET /api/user/preferences
- 2.52: PUT /api/user/preferences

**Remaining Endpoints** (Tasks 2.53-2.60, 60 min)
- Recommendations, learning paths, interactions, etc.

**Total Domain 2:** 60 high-priority endpoints Ã— 3 layers = 180 tasks

---

### Domain 3: User Workflows - Complete Workflow Specs

**Each workflow includes:**
- Prerequisite verification
- Step-by-step execution
- 3-layer validation per step
- Bug handling protocol
- Evidence collection
- Final verification
- Commit

**Workflow 1: Account Creation** (20 tasks)

**Reference:** SESSION_6_EXECUTION_PLAN.md Tasks 1-20

**Task List:**
- 3.1: Navigate to signup page
- 3.2: Click sign up button
- 3.3: Fill signup email
- 3.4: Fill signup password
- 3.5: Fill confirm password
- 3.6: Submit signup form
- 3.7: Verify user created in auth.users (Supabase MCP)
- 3.8: Check email confirmation sent
- 3.9: Confirm email link (or auto-confirm for testing)
- 3.10: Verify email_confirmed_at populated
- 3.11: First login with new account
- 3.12: Verify session created (localStorage token)
- 3.13: Navigate to profile
- 3.14: Verify default preferences created
- 3.15: Screenshot evidence collection
- 3.16: Document in test results
- 3.17: Clean test data
- 3.18: Commit
- 3.19-3.20: Buffer for bug fixing

**Workflow 2-6:** [150 total tasks defined in SESSION_6_EXECUTION_PLAN.md]

---

### Domain 4: Admin Workflows - Complete Workflow Specs

**Workflow 7-14:** [195 total tasks defined in SESSION_7_EXECUTION_PLAN.md]

**Key Workflows:**
- Workflow 7: Resource Editing (20 tasks, modal testing)
- Workflow 8: Bulk Approve (25 tasks, **CRITICAL - NEVER TESTED**)
- Workflow 9: Bulk Reject (20 tasks)
- Workflow 10: Bulk Archive (20 tasks)
- Workflow 11: Bulk Tag (25 tasks, **MOST COMPLEX**)
- Workflow 12: User Management (15 tasks)
- Workflow 13: GitHub Export (30 tasks, awesome-lint validation)
- Workflow 14: AI Enrichment (40 tasks, **NEVER TESTED, HIGH RISK**)

---

### Domain 5: Production Hardening - Complete Task Specs

**Workflow 15-17:** [115 total tasks defined in SESSION_8_EXECUTION_PLAN.md]

**Security Testing (55 tasks):**
- User isolation (RLS with 2 users)
- XSS prevention (script injection)
- SQL injection (malicious queries)
- Rate limiting (100 requests/min)
- Auth boundary testing

**Performance Testing (25 tasks):**
- Lighthouse audits (5 pages)
- Load testing (autocannon, 100 concurrent users)
- Database query optimization
- Bundle size analysis

**Deployment (30 tasks):**
- SSL configuration
- Production environment setup
- Staging deployment + testing
- Production deployment
- Monitoring setup
- Backup configuration

**Cleanup (5 tasks):**
- Remove 269 console.logs
- Fix 48 any types
- Delete unused files
- Final build

---

## Master Task Inventory (516 Primary Tasks)

### By Domain

| Domain | Tasks | Duration | Priority | Status |
|--------|-------|----------|----------|--------|
| 1. Database Verification | 10 | 1h | LOW | 95% done |
| 2. API Endpoints | 180 | 10-12h | CRITICAL | 14% done |
| 3. User Workflows | 150 | 11h | HIGH | 10% done |
| 4. Admin Workflows | 195 | 13h | CRITICAL | 8% done |
| 5. Production Hardening | 115 | 9h | REQUIRED | 0% done |
| **Bug Fixing Buffer** | 140 | 7-9h | OVERHEAD | 22 bugs fixed so far |
| **TOTAL** | **790** | **51-57h** | - | **33-35% overall** |

### By Type

| Type | Count | Examples |
|------|-------|----------|
| Network tests (curl/browser) | 180 | Call endpoint, verify response |
| Database verification (SQL) | 180 | Query tables, verify persistence |
| UI validation (screenshots) | 180 | Check browser state, visual evidence |
| Bug diagnosis (debugging) | 140 | 4-phase systematic debugging |
| Docker rebuilds | 50 | After every code change |
| Documentation updates | 30 | Test results, evidence summaries |
| Commits | 30 | After verified workflows |
| **TOTAL** | **790** | |

### By Completion Status

| Status | Count | Percentage |
|--------|-------|------------|
| âœ… Complete | 114 | 14% |
| ðŸ”„ In Progress | 0 | 0% |
| â³ Pending | 676 | 86% |
| **TOTAL** | **790** | |

---

## Execution Roadmap

### Phase A: API Foundation Testing (180 tasks, 10-12 hours)

**Objective:** Verify all 70 endpoints with 3-layer validation

**Batch 1:** Bookmark + Favorite endpoints (6 tests, 1 hour)
- Tasks 2.1-2.6
- **Checkpoint:** Report bookmark/favorite endpoint status
- **IF ANY FAIL:** Fix before continuing

**Batch 2:** Resource submission + approval (6 tests, 1.5 hours)
- Tasks 2.7-2.12
- **Checkpoint:** Report CRUD endpoint status
- **Expected Bug:** 1-2 bugs in approval workflow

**Batch 3:** Bulk operations (4 tests, 1.5 hours)
- Tasks 2.13-2.16
- **Checkpoint:** Report bulk endpoint status
- **Expected Bugs:** 2-3 bugs (transaction issues, audit logging)
- **CRITICAL:** These have NEVER been tested

**Batch 4:** Admin management (14 tests, 2.5 hours)
- Tasks 2.17-2.30
- **Checkpoint:** Report admin endpoint status
- **Expected Bugs:** 2-3 bugs

**Batch 5:** Integration endpoints (16 tests, 3 hours)
- Tasks 2.31-2.52
- **Checkpoint:** Report integration status
- **Expected Bugs:** 3-5 bugs (external APIs complex)

**Batch 6:** Remaining endpoints (8 tests, 1.5 hours)
- Tasks 2.53-2.60
- **Final Checkpoint:** All 70 endpoints documented
- **Completion Gate:** API_TEST_RESULTS.md has 70 rows, all verified

---

### Phase B: User Experience Validation (150 tasks, 11 hours)

**Reference:** docs/plans/SESSION_6_EXECUTION_PLAN.md

**Batch 1:** Account + Favorites (45 tasks, 4 hours)
- Workflow 1: Account creation (Tasks 3.1-3.20)
- Workflow 2: Favorites flow (Tasks 3.21-3.45)
- **Checkpoint:** Account creation + favorites verified
- **Expected Bugs:** 3-5 bugs

**Batch 2:** Profile + Search (45 tasks, 2.5 hours)
- Workflow 3: Profile & stats (Tasks 3.46-3.60)
- Workflow 4: Search & filter (Tasks 3.61-3.90)
- **Checkpoint:** Profile and search verified
- **Expected Bugs:** 2-3 bugs

**Batch 3:** Journeys + Preferences (60 tasks, 4.5 hours)
- Workflow 5: Learning journeys (Tasks 3.91-3.130)
- Workflow 6: Preferences & recommendations (Tasks 3.131-3.150)
- **Checkpoint:** All user workflows verified
- **Expected Bugs:** 5-7 bugs
- **Completion Gate:** All 6 user workflows pass 3-layer validation

---

### Phase C: Admin Feature Validation (195 tasks, 13 hours)

**Reference:** docs/plans/SESSION_7_EXECUTION_PLAN.md

**Batch 1:** Resource Management (45 tasks, 3 hours)
- Workflow 7: Resource editing (Tasks 4.1-4.20)
- Workflow 8: Bulk approve (Tasks 4.21-4.45)
- **Checkpoint:** Editing + bulk approve verified
- **Expected Bugs:** 4-6 bugs (bulk operations HIGH RISK)

**Batch 2:** More Bulk Operations (65 tasks, 4.5 hours)
- Workflow 9: Bulk reject (Tasks 4.46-4.65)
- Workflow 10: Bulk archive (Tasks 4.66-4.85)
- Workflow 11: Bulk tag (Tasks 4.86-4.110)
- **Checkpoint:** All bulk operations verified
- **Expected Bugs:** 5-8 bugs (transactions, audit logging)

**Batch 3:** User Management (15 tasks, 1 hour)
- Workflow 12: User management (Tasks 4.111-4.125)
- **Checkpoint:** Role management verified

**Batch 4:** Integrations (70 tasks, 4.5 hours)
- Workflow 13: GitHub export (Tasks 4.126-4.155)
- Workflow 14: AI enrichment (Tasks 4.156-4.195)
- **Checkpoint:** All integrations verified
- **Expected Bugs:** 3-5 bugs (external APIs, async processing)
- **Completion Gate:** GitHub export passes awesome-lint, AI enrichment creates tags

---

### Phase D: Production Hardening (115 tasks, 9 hours)

**Reference:** docs/plans/SESSION_8_EXECUTION_PLAN.md

**Batch 1:** Security (55 tasks, 4 hours)
- User isolation testing
- XSS prevention
- SQL injection prevention
- Rate limiting verification
- **Expected Issues:** 2-3 security gaps
- **IF VULNERABILITY:** Invoke systematic-debugging, fix immediately

**Batch 2:** Performance (25 tasks, 2.5 hours)
- Lighthouse audits
- Load testing with autocannon
- Database query optimization
- **Expected Issues:** 1-2 performance bottlenecks

**Batch 3:** Deployment (30 tasks, 2.5 hours)
- SSL configuration
- Production environment setup
- Deployment execution
- Monitoring configuration
- **Expected Issues:** 2-3 deployment errors

**Batch 4:** Cleanup (5 tasks, 30 min)
- Remove console.logs
- Fix any types
- Final verification
- **Completion Gate:** Production deployed and stable

---

### Phase E: Final Documentation & Handoff (20 tasks, 2 hours)

**Tasks:**
- Consolidate all evidence (500+ screenshots, SQL results)
- Create TESTING_EVIDENCE_SUMMARY.md
- Update HONEST_COMPLETION_ASSESSMENT.md (33% â†’ 95%)
- Create PRODUCTION_DEPLOYMENT_SUMMARY.md
- Create MASTER_VERIFICATION_COMPLETE.md
- Final commit with comprehensive message
- Invoke finishing-a-development-branch skill
- Choose merge/PR strategy

---

## Bug Expectation & Handling Budget

### Expected Bug Distribution

**Domain 2 (API Endpoints):** 12-18 bugs
- Authentication issues (expired tokens, wrong headers)
- RLS blocking legitimate requests
- Validation errors
- Transaction failures

**Domain 3 (User Workflows):** 10-15 bugs
- Frontend state management
- React Query cache issues
- Form validation
- Routing problems

**Domain 4 (Admin Workflows):** 12-18 bugs
- Bulk transaction failures (HIGHEST RISK)
- Audit logging gaps
- Modal interactions
- Permission boundary issues
- GitHub API errors
- Claude API rate limiting

**Domain 5 (Production):** 6-10 bugs
- SSL configuration
- Environment variable mismatches
- Deployment script errors
- Performance regressions

**TOTAL EXPECTED: 40-61 bugs**

### Bug Fixing Time Budget

**Per Bug Average:** 50-70 minutes
- Phase 1 Investigation: 15 min
- Phase 2 Pattern Analysis: 10 min
- Phase 3 Hypothesis Testing: 10 min
- Phase 4 Fix Implementation: 15-30 min (includes rebuild)
- Re-testing: 5-10 min

**Total Bug Budget:** 40 bugs Ã— 60 min = 40 hours

**Wait, this exceeds main task time!**

**Realistic Adjustment:** Many bugs will be quick fixes (5-10 min), some complex (2+ hours)

**Revised Budget:**
- 50% quick bugs (20 bugs Ã— 10 min = 200 min = 3.3 hours)
- 40% medium bugs (16 bugs Ã— 45 min = 720 min = 12 hours)
- 10% complex bugs (4 bugs Ã— 120 min = 480 min = 8 hours)
- **Total: 23.3 hours for bug fixing**

**Combined with task execution:** 51h tasks + 23h bugs = **74 hours realistic total**

But existing plans claim 37 hours... Let me reconcile:

**Existing Plans Already Include Bug Buffer:**
- SESSION_5: 4.75h baseline + 1.5h buffer = 6.25h
- SESSION_6: 8h baseline + 3h buffer = 11h
- SESSION_7: 10h baseline + 3h buffer = 13h
- SESSION_8: 7h baseline + 2h buffer = 9h
- **Total: 39.25 hours with 9.5h bug buffer**

So existing plans are realistic with 60% bug overhead built in.

---

## Success Criteria Per Domain

### Domain 1: Database âœ…
- âœ… All FKs documented and tested
- âœ… All indexes verified with EXPLAIN
- âœ… All RLS policies tested
- âœ… Schema audit complete

**Current:** 95% complete

---

### Domain 2: API Endpoints

**Complete When:**
- âœ… All 70 endpoints in API_TEST_RESULTS.md
- âœ… Each endpoint has: Network âœ… | Database âœ… | UI âœ…
- âœ… All auth endpoints tested with valid/invalid tokens
- âœ… All admin endpoints tested with admin/non-admin users
- âœ… All errors handled (400, 401, 403, 404, 500 responses documented)

**Evidence Required:**
- API_TEST_RESULTS.md with 70 complete rows
- ~200 screenshots (before/after for each test)
- ~100 SQL query results

---

### Domain 3: User Workflows

**Complete When:**
- âœ… All 6 user workflows execute end-to-end without errors
- âœ… Account creation works (signup â†’ confirm â†’ login)
- âœ… Favorites work (add â†’ profile â†’ remove)
- âœ… Bookmarks work (add â†’ notes â†’ page â†’ remove)
- âœ… Profile stats accurate (match database)
- âœ… Search & filters functional (text, category, tags, combined)
- âœ… Learning journeys work (browse â†’ enroll â†’ progress â†’ complete)
- âœ… Preferences & recommendations work (set â†’ persist â†’ affect recommendations)

**Evidence Required:**
- ~150 screenshots (workflow steps)
- ~50 SQL verifications
- User flow diagram with evidence

---

### Domain 4: Admin Workflows

**Complete When:**
- âœ… Resource editing works (modal â†’ save â†’ verify database + public)
- âœ… Bulk approve works (select N â†’ approve â†’ verify N approved + audit log + public)
- âœ… Bulk reject works
- âœ… Bulk archive works (verify removed from public)
- âœ… Bulk tag works (tags created + junctions verified)
- âœ… User management works (role changes persist)
- âœ… GitHub export generates awesome-lint compliant markdown
- âœ… AI enrichment completes and creates tags
- âœ… **CRITICAL:** Audit logging works for ALL admin actions

**Evidence Required:**
- ~200 screenshots
- ~100 SQL queries (especially audit_log verification)
- Exported awesome-list.md passing awesome-lint
- Enrichment job completion with tags in database

---

### Domain 5: Production Hardening

**Complete When:**
- âœ… User isolation verified (User A cannot see User B's data)
- âœ… XSS prevented (script tags escaped)
- âœ… SQL injection prevented (parameterized queries working)
- âœ… Rate limiting active (429 after limit)
- âœ… Performance targets met (Lighthouse > 80, p95 < 200ms, 100 users no crash)
- âœ… Deployed to production with SSL
- âœ… Monitoring active (uptime, errors)
- âœ… Backups configured
- âœ… Clean codebase (no debug logs, no unused code)

**Evidence Required:**
- Security test results (no vulnerabilities)
- Performance benchmark report
- Production deployment confirmation
- Uptime monitoring dashboard link

---

## Detailed Task Examples (Following writing-plans Format)

### Example from Domain 2: API Endpoint Testing

**Task 2.1: Test POST /api/bookmarks/:id Endpoint**

**Files:**
- Test: API via curl
- Verify: docs/API_TEST_RESULTS.md:29
- Database: Supabase PostgreSQL user_bookmarks table

**Step 1: Get admin JWT token**

```bash
# Open browser
open http://localhost:3000/login

# Manual: Login as admin@test.com / Admin123!
# Open DevTools â†’ Application â†’ Local Storage
# Find key: sb-jeyldoypdkgsrfdhdcmm-auth-token
# Copy value, extract access_token field

export ADMIN_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
```

**Step 2: Call bookmark endpoint**

```bash
curl -X POST http://localhost:3000/api/bookmarks/afc5937b-28eb-486c-961f-38b5d2418b2a \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -v
```

Expected Output:
```
< HTTP/1.1 200 OK
< Content-Type: application/json
{"success":true,"bookmark":{...}}
```

**IF 401 Unauthorized:**
- Token expired â†’ Get fresh token (Step 1)
- Token malformed â†’ Check token extraction
- Middleware broken â†’ systematic-debugging server/supabaseAuth.ts

**IF 500 Internal Server Error:**
- Check Docker logs: `docker-compose logs web | tail -50`
- Invoke systematic-debugging skill
- Likely causes: RLS blocking INSERT, invalid UUID, database connection

**Step 3: Verify database (Layer 2)**

```sql
-- Via Supabase MCP: mcp__supabase__execute_sql
SELECT user_id, resource_id, notes, created_at
FROM user_bookmarks
WHERE user_id = '58c592c5-548b-4412-b4e2-a9df5cac5397'
  AND resource_id = 'afc5937b-28eb-486c-961f-38b5d2418b2a';
```

Expected: 1 row returned
- user_id matches admin UUID
- resource_id matches test resource
- created_at within last 2 minutes
- notes is NULL or empty string

**IF NO ROW:**
- API returned 200 but database has no row
- **CRITICAL BUG:** Response lying OR RLS blocking INSERT OR transaction rolled back
- Invoke systematic-debugging
- Check: RLS policies on user_bookmarks
- Check: Server logs for transaction errors
- Check: Network response actually returned 200 (not cached)

**Step 4: Verify UI (Layer 3)**

```bash
# Via superpowers-chrome MCP
mcp__plugin_superpowers-chrome_chrome__use_browser({
  action: "navigate",
  payload: "http://localhost:3000/bookmarks"
})

# Check auto-captured page.md for resource title
# Verify: Resource appears in bookmarks list
```

Expected: page.md contains "EBU R128 Introduction" (test resource title)

**IF NOT IN LIST:**
- Network âœ…, Database âœ…, but UI shows empty
- Frontend not fetching OR RLS blocking GET endpoint
- Invoke systematic-debugging
- Check: GET /api/bookmarks endpoint
- Check: React Query fetching
- Check: RLS policy for SELECT on user_bookmarks

**Step 5: Clean test data**

```sql
DELETE FROM user_bookmarks
WHERE resource_id = 'afc5937b-28eb-486c-961f-38b5d2418b2a';
```

**Step 6: Document result**

Update docs/API_TEST_RESULTS.md:
```markdown
| 29 | POST /api/bookmarks/:id | âœ… PASS | 200 OK | Row created in user_bookmarks | Resource appears in /bookmarks | Screenshot: /tmp/bookmark-add-verified.png |
```

**Step 7: Commit (if this completes a logical group)**

```bash
git add docs/API_TEST_RESULTS.md
git commit -m "test: Verify POST /api/bookmarks/:id endpoint

- Called with admin JWT token
- Response: 200 OK
- Database: Row created in user_bookmarks
- UI: Resource appears in /bookmarks page
- All 3 layers verified âœ…
- Endpoint: WORKING"
```

**Total Time:** 10 min (happy path) OR 40-70 min (if bug found and fixed)

---

### Example from Domain 3: User Workflow Testing

**Workflow 2: Favorites Flow - Complete Task Breakdown**

**Task 3.21: Login as Test User**

**File:** client/src/pages/Login.tsx

**Step 1: Navigate to login**
```
superpowers-chrome: navigate to http://localhost:3000/login
```

**Step 2: Fill email**
```
superpowers-chrome: type into input[type='email']
Value: "testuser-session6@example.com"
```

**Step 3: Fill password**
```
superpowers-chrome: type into input[type='password']
Value: "TestUser123!"
```

**Step 4: Submit**
```
superpowers-chrome: type "\n" into password field (submits form)
OR click button[type='submit']
```

**Step 5: Verify redirect**
```
Check page.md: URL should be "/" (homepage)
Check page.md: User menu visible with email
```

**Step 6: Verify session**
```javascript
superpowers-chrome: eval
payload: "localStorage.getItem('sb-jeyldoypdkgsrfdhdcmm-auth-token')"

Expected: Returns JSON string with access_token
```

**IF LOGIN FAILS:**
- Invoke systematic-debugging
- Check: Supabase connection
- Check: Email confirmed in auth.users
- Check: Password complexity requirements
- Fix, rebuild if needed, restart Task 3.21

---

**Task 3.22-3.45:** [Continue with favorite add, view, remove - 23 more tasks]

**Reference:** SESSION_6_EXECUTION_PLAN.md Tasks 21-45 for complete details

---

### Example from Domain 4: Admin Workflow Testing

**Workflow 8: Bulk Approve - Critical Task Example**

**Task 4.34: Verify Database Updated (CRITICAL VERIFICATION)**

**This task validates the MOST IMPORTANT admin feature**

**Step 1: Query resources table**

```sql
-- Get resource IDs from Task 4.22 (noted when creating test resources)
-- Example IDs: [id1, id2, id3, id4, id5]

SELECT
  id,
  title,
  status,
  approved_by,
  approved_at,
  updated_at
FROM resources
WHERE id IN (
  'a1234567-89ab-cdef-0123-456789abcdef',
  'b2345678-89ab-cdef-0123-456789abcdef',
  'c3456789-89ab-cdef-0123-456789abcdef',
  'd4567890-89ab-cdef-0123-456789abcdef',
  'e5678901-89ab-cdef-0123-456789abcdef'
)
ORDER BY title;
```

**Expected Results (ALL 5 MUST BE TRUE):**

1. âœ… status = 'approved' (was 'pending')
2. âœ… approved_by = '58c592c5-548b-4412-b4e2-a9df5cac5397' (admin UUID)
3. âœ… approved_at IS NOT NULL
4. âœ… approved_at > (NOW() - INTERVAL '2 minutes') (recent)
5. âœ… updated_at > (NOW() - INTERVAL '2 minutes') (recently updated)

**Step 2: Verify audit log (MOST CRITICAL - Session 2's claim validation)**

```sql
SELECT
  resource_id,
  action,
  performed_by,
  changes,
  notes,
  created_at
FROM resource_audit_log
WHERE resource_id IN ('[id1]', '[id2]', '[id3]', '[id4]', '[id5]')
  AND action LIKE '%approve%'
ORDER BY created_at DESC;
```

**Expected Results:**
- âœ… Exactly 5 rows (one per resource)
- âœ… action = 'approved' OR 'bulk_approved'
- âœ… performed_by = admin UUID
- âœ… created_at within last 2 minutes
- âœ… changes JSONB contains {"status":"pendingâ†’approved"} or similar

**Step 3: Verify transaction integrity**

```sql
-- Check if ANY resources in test set are NOT approved (partial transaction)
SELECT COUNT(*) as not_approved
FROM resources
WHERE id IN ('[id1]', '[id2]', '[id3]', '[id4]', '[id5]')
  AND status != 'approved';
```

Expected: not_approved = 0 (all 5 approved atomically)

**IF ANY VERIFICATION FAILS:**

**Failure Scenario A: Some approved, some still pending**
```
SELECT id, title, status FROM resources WHERE id IN (...)
Result: 3 approved, 2 pending

ROOT CAUSE: Transaction not atomic or partial rollback
SEVERITY: CRITICAL (data corruption risk)

â†’ STOP ALL TESTING
â†’ Invoke: root-cause-tracing skill
â†’ Trace: Bulk endpoint â†’ storage.bulkApproveResources() â†’ db.transaction() â†’ find break point
â†’ Hypothesis: Transaction commits before all updates OR missing transaction wrapper
â†’ Fix: Ensure all updates in single transaction with proper error handling
â†’ Rebuild Docker
â†’ Clean test data: DELETE test resources
â†’ RESTART from Task 4.21 (create fresh 5 pending resources)
```

**Failure Scenario B: All approved but NO audit log**
```
SELECT COUNT(*) FROM resource_audit_log WHERE resource_id IN (...)
Result: 0 (expected 5)

ROOT CAUSE: Audit logging not implemented for bulk operations
SEVERITY: CRITICAL (compliance requirement)

â†’ STOP ALL TESTING
â†’ Invoke: systematic-debugging skill
â†’ Phase 1: Check server/routes.ts bulk endpoint implementation
â†’ Phase 2: Compare with single approve endpoint (which DOES log)
â†’ Phase 3: Hypothesis - audit log call missing from bulk endpoint
â†’ Phase 4: Add audit log creation:
   File: server/routes.ts:XXX (bulk endpoint)
   Add after successful update:
   ```typescript
   // Create audit log entries for bulk operation
   for (const resourceId of successfulIds) {
     await storage.createAuditLog({
       resourceId,
       action: 'bulk_approved',
       performedBy: req.user.id,
       changes: { status: 'pending â†’ approved', bulk: true }
     });
   }
   ```
â†’ Rebuild Docker
â†’ Clean test data
â†’ RESTART from Task 4.21
```

**Failure Scenario C: All approved but approved_by is NULL**
```
SELECT approved_by FROM resources WHERE id IN (...)
Result: All NULL (expected admin UUID)

ROOT CAUSE: req.user.id not passed to storage method
SEVERITY: HIGH (audit trail incomplete)

â†’ STOP
â†’ Invoke: systematic-debugging
â†’ Fix: Pass req.user.id to storage.bulkApproveResources(resourceIds, userId)
â†’ Update storage method signature
â†’ Rebuild, clean, restart Task 4.21
```

**AFTER ALL VERIFICATIONS PASS:**
- Screenshot final database state
- Document in: docs/TESTING_EVIDENCE/bulk-approve-verified.md
- Update: docs/API_TEST_RESULTS.md (mark bulk endpoint âœ…)
- Continue: Task 4.35 (Verify public visibility)

**Total Task Time:** 5 min (if passes) OR 60-90 min (if bug found and fixed)

---

## Tool-Task Matrix

**Which tool for which task:**

### superpowers-chrome MCP
**Use for:** 450+ tasks
- All browser navigation
- All UI interactions (click, type, submit)
- Visual verification (page.md, screenshots)
- Network request inspection
- Console error checking

**Auto-captured after navigation:**
- page.md (accessibility tree in markdown)
- page.html (full HTML)
- screenshot.png (visual state)

**Check page.md BEFORE using extract** - often auto-capture is sufficient

### Supabase MCP
**Use for:** 200+ tasks
- All SQL queries (verification)
- Database state checks
- Auth user queries (auth.users table)
- RLS policy testing

**Commands:**
```typescript
mcp__supabase__execute_sql({ query: "SELECT ..." })
mcp__supabase__list_tables()
```

### Bash
**Use for:** 150+ tasks
- Docker operations (build, restart, logs)
- curl API testing
- File operations
- Git commits
- Script execution

**Common Commands:**
```bash
docker-compose down && build && up -d
curl -H "Authorization: Bearer $TOKEN" http://...
npm run check
git add . && git commit -m "..."
```

### Sequential Thinking MCP
**Use for:** 10-20 tasks
- Complex debugging (when systematic-debugging Phase 3 needs deep analysis)
- Architectural decisions
- Planning complex fixes
- Root cause analysis for mysterious bugs

---

## Commit Strategy

**Commit frequency:** After every verified workflow (not every task)

**Commit after:**
- âœ… 3-6 endpoints verified (Domain 2)
- âœ… 1 complete user workflow (Domain 3)
- âœ… 1 complete admin workflow (Domain 4)
- âœ… Security phase complete (Domain 5)
- âœ… Bug fixed and re-tested

**Commit Message Format:**
```
type: brief description

- Detail 1 (what was tested)
- Detail 2 (what was verified)
- Verification: [How verified - 3 layers]
- Evidence: [Screenshot/SQL references]
- [Optional] Fixed: Bug description
- [Optional] Root cause: Analysis
```

**Types:**
- test: Verification/testing work
- fix: Bug fixes
- feat: New features (rare in verification plan)
- docs: Documentation updates
- refactor: Code cleanup

**Example Commits:**
```bash
git commit -m "test: Verify bookmark and favorite endpoints

- POST /api/bookmarks/:id â†’ 200 OK, row created
- DELETE /api/bookmarks/:id â†’ 200 OK, row deleted
- GET /api/bookmarks â†’ 200 OK, returns bookmarks
- POST /api/favorites/:id â†’ 200 OK, row created
- DELETE /api/favorites/:id â†’ 200 OK, row deleted
- GET /api/favorites â†’ 200 OK, returns favorites

Verification: All 3 layers (Network âœ… Database âœ… UI âœ…)
Evidence: 12 screenshots, 6 SQL queries
API_TEST_RESULTS.md: 6/70 endpoints verified"

git commit -m "test: Verify complete favorites workflow end-to-end

- User login â†’ category â†’ click favorite â†’ verify DB row
- Navigate to profile â†’ verify favorite shown
- Click remove â†’ verify DB deletion
- All 3 layers verified at each step

Evidence: docs/TESTING_EVIDENCE/favorites-workflow.md
Fixed: Favorite button selector (was wrong CSS class)
Root cause: Button CSS class changed in recent shadcn update"
```

---

## Honest Completion Tracking

**Before Starting Master Plan:**
- Features verified: 11/33 = 33%
- Endpoints tested: 10/70 = 14%
- Workflows complete: 2/14 = 14%

**After Domain 2 (API Endpoints):**
- Features: ~15/33 = 45% (endpoint tests prove backend works)
- Endpoints: 70/70 = 100%
- Workflows: 2/14 = 14%

**After Domain 3 (User Workflows):**
- Features: ~21/33 = 64% (all user features verified)
- Workflows: 8/14 = 57%

**After Domain 4 (Admin Workflows):**
- Features: ~29/33 = 88% (all admin features verified)
- Workflows: 14/14 = 100%

**After Domain 5 (Production):**
- Features: 31/33 = 94% (all verified + deployed)
- Security: Hardened
- Performance: Benchmarked
- Deployed: Production

**Final Honest Completion: 94-95%**

**Remaining 5-6%:**
- Advanced analytics (ML-powered insights) - Future
- Email notifications - Future

---

## Risk Assessment

### HIGH RISK Tasks (Likely to Find Bugs)

**Bulk Operations** (Domain 4, Workflows 8-11):
- Risk: Transaction failures, partial commits, deadlocks
- Mitigation: Systematic debugging mandatory, database verification critical
- **Never tested** - Unknown failure modes

**AI Enrichment** (Domain 4, Workflow 14):
- Risk: Claude API rate limits, timeout, malformed responses
- Mitigation: Small batch size (5), job monitoring, error handling
- **Never tested** - Unknown Claude integration issues

**GitHub Export** (Domain 4, Workflow 13):
- Risk: Markdown generation errors, awesome-lint failures
- Mitigation: Dry-run first, iterative lint fixing
- **Partially tested** - Code exists but validation never run

**Security Testing** (Domain 5, Workflow 15):
- Risk: Actual vulnerabilities found (RLS, XSS, SQL injection)
- Mitigation: Immediate fix required, no deployment until patched
- **Never tested** - Unknown security posture

### MEDIUM RISK Tasks

**User Workflows** (Domain 3):
- Risk: Form validation, state management, routing
- Mitigation: Well-tested patterns, bugs should be straightforward

**API Endpoint Testing** (Domain 2):
- Risk: Auth issues, RLS blocking, response structure mismatches
- Mitigation: Standard testing pattern, most bugs quick fixes

### LOW RISK Tasks

**Database Verification** (Domain 1):
- Risk: Minimal (95% done, just documentation)

**Code Cleanup** (Domain 5):
- Risk: Minimal (delete operations, lint fixes)

---

## Time Investment Summary

### Existing Sessions (Completed)
- Session 1: 4 hours (database + backend migration)
- Session 2: 1.5 hours (frontend unblocking + validation)
- Session 3: 12 hours (admin panel build + bugs)
- Session 4: 2 hours (code audit + documentation)
- Session 5: 10 hours (data model architecture fix)
- **Subtotal: 29.5 hours invested**

### Remaining Domains (This Master Plan)
- Domain 1: 1 hour (documentation)
- Domain 2: 10-12 hours (API testing)
- Domain 3: 11 hours (user workflows)
- Domain 4: 13 hours (admin workflows)
- Domain 5: 9 hours (production hardening)
- **Subtotal: 44-46 hours remaining**

### GRAND TOTAL
- **73.5-75.5 hours** for complete, honest 95% verification
- Original estimate: "50-65 hours" (from REPLIT_TO_SUPABASE_MIGRATION_PLAN.md)
- **Accurate within 20%** (estimate was good)

---

## Next Steps (Immediate Actions)

### 1. Review This Master Plan
- Read completely (this is the consolidation you requested)
- Verify: All tasks from SESSION_5-8_EXECUTION_PLANs included
- Verify: Skill invocations specified at correct points
- Verify: Mandatory protocols included (systematic-debugging, 3-layer, Docker rebuild)

### 2. Choose Execution Approach

**Option A: Execute from Current State**
- Start with Domain 1 (database documentation - 1 hour)
- Continue to Domain 2 (API endpoints - critical)
- Use executing-plans skill in batches

**Option B: Focus on High-Risk First**
- Jump to Domain 4, Workflow 8 (Bulk Approve - NEVER tested)
- Verify bulk operations work
- Then systematically complete remaining

**Option C: Complete Session 5 Gaps First**
- Finish remaining 36 tasks from SESSION_5_EXECUTION_PLAN
- Then continue with master plan

### 3. Confirm Tool Access
- âœ… superpowers-chrome MCP working
- âœ… Supabase MCP connected
- âœ… Docker running
- âœ… Database accessible

### 4. Begin Execution

**When ready, invoke:**
```
/superpowers:execute-plan docs/plans/2025-11-30-master-verification-execution-plan.md
```

**Or continue in this session with batch execution:**
- I'll execute 20-30 tasks
- Report results
- Get feedback
- Continue next batch

---

## References

**Source Documents (35+ docs consolidated):**
- âœ… 8 Serena memories (session context, architecture understanding)
- âœ… 4 session execution plans (SESSION_5-8_EXECUTION_PLAN.md)
- âœ… 3 comprehensive inventories (REMAINING_WORK, HONEST_COMPLETION, 2025-11-30-complete-verification)
- âœ… 10+ status reports (SESSION_X_COMPLETE.md files)
- âœ… 8 honest reflection docs (gaps, bugs, learnings)
- âœ… CLAUDE.md (architecture reference)
- âœ… Git history (50 commits analyzed)

**Key Documents:**
- Task source: docs/plans/SESSION_[5-8]_EXECUTION_PLAN.md
- Completion truth: docs/HONEST_COMPLETION_ASSESSMENT.md
- Bug protocols: docs/plans/2025-11-30-complete-verification-testing.md
- Architecture: CLAUDE.md, docs/ARCHITECTURE.md
- Database: docs/DATABASE_SCHEMA.md

**Total Lines Analyzed:** ~50,000+ lines of documentation and code

---

## Plan Status

**Status:** âœ… COMPREHENSIVE MASTER PLAN COMPLETE

**Consolidation:**
- âœ… All 516 tasks from existing plans included
- âœ… Skill invocation protocols specified
- âœ… Mandatory debugging workflows integrated
- âœ… 3-layer validation requirements defined
- âœ… Evidence collection protocols specified
- âœ… Honest completion tracking formulas provided

**Execution Ready:** YES

**Next Action:** Invoke executing-plans skill with this master plan, OR choose execution approach above

**Estimated Completion Time:** 44-46 hours for remaining domains (73-75 hours total project)

**Honest Target:** 95% completion (31/33 features verified + production deployed)

**Current:** 33-35% completion (11/33 features verified)

**Remaining:** 60-62 percentage points across 676 pending tasks

---

**Master Plan Created:** 2025-11-30
**Consolidates:** 35+ source documents
**Total Tasks:** 516 primary + 140 bug-fixing + 134 meta-tasks = 790 total
**Comprehensive:** Yes (every task has: tool, duration, validation, IF FAILS protocol)

ðŸš€ **Ready for meticulous execution with systematic debugging at every failure point**
